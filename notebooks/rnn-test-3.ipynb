{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# TEST = r'C:\\Users\\arish\\open-source\\psi-detection\\data\\intermediate\\H.sapiens100\\test.csv'\n",
    "TRAIN = r'C:\\Users\\arish\\open-source\\psi-detection\\data\\intermediate\\hsapiens495\\train.csv'\n",
    "# VALID = r'C:\\Users\\arish\\open-source\\psi-detection\\data\\intermediate\\H.sapiens100\\valid.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def space_sequence(dataframe: pd.DataFrame):\n",
    "    dataframe['x'] = dataframe['x'].map(list).map(lambda x: ' '.join(x))\n",
    "\n",
    "\n",
    "def prepare_single_sequence(sequence: str):\n",
    "    return ' '.join(list(sequence))\n",
    "\n",
    "\n",
    "def split_dataframe(dataframe: pd.DataFrame):\n",
    "    return dataframe['x'].values, dataframe['y'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(TRAIN, header=None)\n",
    "train_data.columns = ['x', 'y']\n",
    "space_sequence(train_data)\n",
    "\n",
    "# valid_data = pd.read_csv(VALID, header=None)\n",
    "# valid_data.columns = ['x', 'y']\n",
    "# space_sequence(valid_data)\n",
    "#\n",
    "# test_data = pd.read_csv(TEST, header=None)\n",
    "# test_data.columns = ['x', 'y']\n",
    "# space_sequence(test_data)\n",
    "\n",
    "# test_data = split_dataframe(test_data)\n",
    "train_data = split_dataframe(train_data)\n",
    "# valid_data = split_dataframe(valid_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(train_data[0], train_data[1], test_size=0.2, random_state=1)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.25, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 4 + 2\n",
    "BATCH_SIZE = 64"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=VOCAB_SIZE,\n",
    "        output_dim=64,\n",
    "        mask_zero=False,\n",
    "    ),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.50359607],\n       [0.50221145],\n       [0.50271153],\n       [0.49999255],\n       [0.498415  ],\n       [0.5003724 ],\n       [0.49881646],\n       [0.49936706],\n       [0.5014425 ],\n       [0.5016416 ],\n       [0.5017632 ],\n       [0.49708444],\n       [0.50024813],\n       [0.5007146 ],\n       [0.5019153 ],\n       [0.5020216 ],\n       [0.50063384],\n       [0.49884403],\n       [0.49914393],\n       [0.5004883 ],\n       [0.50326264],\n       [0.50090206],\n       [0.49963796],\n       [0.49692494],\n       [0.50263554],\n       [0.4975864 ],\n       [0.49873704],\n       [0.5000389 ],\n       [0.4985265 ],\n       [0.5011708 ],\n       [0.50138223],\n       [0.49898332],\n       [0.5017166 ],\n       [0.49883205],\n       [0.5008302 ],\n       [0.50166404],\n       [0.4997287 ],\n       [0.50159377],\n       [0.49831915],\n       [0.5010004 ],\n       [0.500267  ],\n       [0.49954024],\n       [0.49880388],\n       [0.5011046 ],\n       [0.49339545],\n       [0.50071913],\n       [0.5020506 ],\n       [0.50212675],\n       [0.499387  ],\n       [0.4995726 ],\n       [0.50111794],\n       [0.49850282],\n       [0.50368893],\n       [0.50268424],\n       [0.50135   ],\n       [0.5006308 ],\n       [0.49705228],\n       [0.5014292 ],\n       [0.5015611 ],\n       [0.4991861 ],\n       [0.50445336],\n       [0.502518  ],\n       [0.49951294],\n       [0.49883664],\n       [0.5036042 ],\n       [0.5000288 ],\n       [0.5024033 ],\n       [0.50225073],\n       [0.49880055],\n       [0.5011507 ],\n       [0.50040597],\n       [0.50115323],\n       [0.5002868 ],\n       [0.49945047],\n       [0.49926034],\n       [0.49911782],\n       [0.498967  ],\n       [0.49801618],\n       [0.49561706],\n       [0.4987114 ],\n       [0.50097543],\n       [0.49915886],\n       [0.49849433],\n       [0.50048524],\n       [0.50244236],\n       [0.50125974],\n       [0.50019395],\n       [0.5029348 ],\n       [0.501081  ],\n       [0.49908414],\n       [0.50166345],\n       [0.49937275],\n       [0.50179785],\n       [0.5001964 ],\n       [0.49824136],\n       [0.49900553],\n       [0.50064355],\n       [0.50274837],\n       [0.50136334],\n       [0.499344  ],\n       [0.5008732 ],\n       [0.50026137],\n       [0.49800295],\n       [0.5006984 ],\n       [0.5010724 ],\n       [0.49418435],\n       [0.501337  ],\n       [0.5015856 ],\n       [0.49855095],\n       [0.5007253 ],\n       [0.50193787],\n       [0.50361794],\n       [0.49892527],\n       [0.49911648],\n       [0.5015214 ],\n       [0.49844974],\n       [0.5008457 ],\n       [0.49545467],\n       [0.50114125],\n       [0.49619284],\n       [0.50164807],\n       [0.5036487 ],\n       [0.499786  ],\n       [0.4988132 ],\n       [0.4995612 ],\n       [0.49821705],\n       [0.49752462],\n       [0.50161403],\n       [0.50132227],\n       [0.49912092],\n       [0.49758494],\n       [0.5011594 ],\n       [0.4993522 ],\n       [0.5018813 ],\n       [0.50006485],\n       [0.50035137],\n       [0.4995194 ],\n       [0.5006539 ],\n       [0.5026493 ],\n       [0.49816445],\n       [0.49958572],\n       [0.49967474],\n       [0.50208825],\n       [0.5020979 ],\n       [0.4995472 ],\n       [0.4996052 ],\n       [0.49871057],\n       [0.49940366],\n       [0.50301284],\n       [0.5022416 ],\n       [0.498709  ],\n       [0.50090146],\n       [0.5026829 ],\n       [0.49895462],\n       [0.5012981 ],\n       [0.50246537],\n       [0.5005739 ],\n       [0.4964465 ],\n       [0.49988496],\n       [0.50070775],\n       [0.49918985],\n       [0.5019924 ],\n       [0.49885783],\n       [0.49974746],\n       [0.49955496],\n       [0.499824  ],\n       [0.499161  ],\n       [0.50160813],\n       [0.4971173 ],\n       [0.5023397 ],\n       [0.5019244 ],\n       [0.49825823],\n       [0.50233716],\n       [0.49795875],\n       [0.4993966 ],\n       [0.49954715],\n       [0.498841  ],\n       [0.49922785],\n       [0.5003733 ],\n       [0.49994752],\n       [0.50059706],\n       [0.49834242],\n       [0.49976662],\n       [0.49604267],\n       [0.50118566],\n       [0.50024146],\n       [0.49955618],\n       [0.5003435 ],\n       [0.49965093],\n       [0.4966302 ],\n       [0.50214505],\n       [0.50016874],\n       [0.49843195],\n       [0.49838203],\n       [0.5013888 ],\n       [0.49553475],\n       [0.5020184 ],\n       [0.4968723 ],\n       [0.5025482 ],\n       [0.50122195],\n       [0.50068814],\n       [0.49672437],\n       [0.5004548 ],\n       [0.50188464],\n       [0.49624085],\n       [0.49899644],\n       [0.50099385],\n       [0.49737006],\n       [0.5000145 ],\n       [0.5010817 ],\n       [0.5019311 ],\n       [0.49968392],\n       [0.49872273],\n       [0.4997997 ],\n       [0.49779293],\n       [0.5025572 ],\n       [0.5006405 ],\n       [0.49991155],\n       [0.5016992 ],\n       [0.501322  ],\n       [0.503772  ],\n       [0.5008363 ],\n       [0.5029585 ],\n       [0.5003291 ],\n       [0.49837753],\n       [0.5003243 ],\n       [0.5011434 ],\n       [0.497497  ],\n       [0.50131565],\n       [0.49797153],\n       [0.49929777],\n       [0.49706006],\n       [0.498445  ],\n       [0.5030996 ],\n       [0.4992993 ],\n       [0.5011258 ],\n       [0.5030274 ],\n       [0.49570736],\n       [0.5003332 ],\n       [0.4982313 ],\n       [0.49837524],\n       [0.4950546 ],\n       [0.49994174],\n       [0.49788612],\n       [0.49688494],\n       [0.5006607 ],\n       [0.50046813],\n       [0.5004105 ],\n       [0.5004855 ],\n       [0.5016055 ],\n       [0.50118375],\n       [0.5015997 ],\n       [0.4989654 ],\n       [0.5001283 ],\n       [0.50034446],\n       [0.49914992],\n       [0.4994005 ],\n       [0.49836925],\n       [0.49986792],\n       [0.5004863 ],\n       [0.50190943],\n       [0.49970582],\n       [0.5010347 ],\n       [0.5011458 ],\n       [0.50239   ],\n       [0.49801034],\n       [0.50109977],\n       [0.49902815],\n       [0.5002985 ],\n       [0.5002293 ],\n       [0.49933937],\n       [0.5005005 ],\n       [0.4980358 ],\n       [0.49996528],\n       [0.5012874 ],\n       [0.5028302 ],\n       [0.50272304],\n       [0.4985459 ],\n       [0.50159615],\n       [0.49927545],\n       [0.49928856],\n       [0.5009504 ],\n       [0.49872538],\n       [0.49597323],\n       [0.49990827],\n       [0.50105685],\n       [0.5016266 ],\n       [0.50129914],\n       [0.5014782 ],\n       [0.4988866 ],\n       [0.4984922 ],\n       [0.5022796 ],\n       [0.5017057 ],\n       [0.500399  ],\n       [0.5020844 ],\n       [0.50015545],\n       [0.5018009 ],\n       [0.5008905 ],\n       [0.498929  ],\n       [0.50393057],\n       [0.4974981 ],\n       [0.5014208 ],\n       [0.499659  ],\n       [0.50321144],\n       [0.50040275],\n       [0.4966894 ],\n       [0.5030976 ],\n       [0.50117344],\n       [0.49885923],\n       [0.5015091 ],\n       [0.4970679 ],\n       [0.50260377],\n       [0.4999261 ],\n       [0.50063986],\n       [0.5016818 ],\n       [0.49632704],\n       [0.50122595],\n       [0.49925008],\n       [0.5016207 ],\n       [0.4994616 ],\n       [0.4993375 ],\n       [0.5003973 ],\n       [0.50037706],\n       [0.5005314 ],\n       [0.50080734],\n       [0.50216216],\n       [0.49929485],\n       [0.5000236 ],\n       [0.49725714],\n       [0.501896  ],\n       [0.5001045 ],\n       [0.5023501 ],\n       [0.49805486],\n       [0.4991713 ],\n       [0.4984684 ],\n       [0.49937847],\n       [0.5020595 ],\n       [0.49973747],\n       [0.5017185 ],\n       [0.49733526],\n       [0.50055045],\n       [0.50164026],\n       [0.5026091 ],\n       [0.5012804 ],\n       [0.50242805],\n       [0.49707592],\n       [0.49858868],\n       [0.5019367 ],\n       [0.50024015],\n       [0.5014417 ],\n       [0.49928334],\n       [0.50018084],\n       [0.50042516],\n       [0.49880612],\n       [0.5008802 ],\n       [0.4971803 ],\n       [0.5003152 ],\n       [0.50171137],\n       [0.4994957 ],\n       [0.49929088],\n       [0.5027374 ],\n       [0.50047034],\n       [0.5031926 ],\n       [0.50212663],\n       [0.503258  ],\n       [0.4998474 ],\n       [0.5017366 ],\n       [0.49725124],\n       [0.50044686],\n       [0.5012587 ],\n       [0.49844435],\n       [0.4967118 ],\n       [0.5001194 ],\n       [0.49860772],\n       [0.49995932],\n       [0.5012082 ],\n       [0.5009974 ],\n       [0.49801457],\n       [0.5000592 ],\n       [0.49660245],\n       [0.5035188 ],\n       [0.50097525],\n       [0.503314  ],\n       [0.5010659 ],\n       [0.5008331 ],\n       [0.5030408 ],\n       [0.5008095 ],\n       [0.49587417],\n       [0.50164205],\n       [0.50036246],\n       [0.50001943],\n       [0.50020194],\n       [0.50322497],\n       [0.50169694],\n       [0.49709883],\n       [0.49888548],\n       [0.49979985],\n       [0.49831325],\n       [0.50063354],\n       [0.50350744],\n       [0.50112617],\n       [0.5000742 ],\n       [0.5006022 ],\n       [0.4993218 ],\n       [0.49866903],\n       [0.49886036],\n       [0.5014828 ],\n       [0.49876893],\n       [0.50110555],\n       [0.49775034],\n       [0.4999623 ],\n       [0.50065154],\n       [0.49874854],\n       [0.49700215],\n       [0.5002018 ],\n       [0.5025268 ],\n       [0.49887282],\n       [0.49828747],\n       [0.49877292],\n       [0.5013769 ],\n       [0.4996055 ],\n       [0.50234526],\n       [0.5012741 ],\n       [0.50150234],\n       [0.49723887],\n       [0.5022226 ],\n       [0.50238883],\n       [0.49985147],\n       [0.50004673],\n       [0.50201803],\n       [0.49966586],\n       [0.49980336],\n       [0.4981918 ],\n       [0.5016298 ],\n       [0.49849245],\n       [0.50127685],\n       [0.4997813 ],\n       [0.49830046],\n       [0.49886456],\n       [0.49940333],\n       [0.5003616 ],\n       [0.49951547],\n       [0.501031  ],\n       [0.5007576 ],\n       [0.5019037 ],\n       [0.49919802],\n       [0.4972144 ],\n       [0.49918115],\n       [0.50083184],\n       [0.501881  ],\n       [0.50110936],\n       [0.5028024 ],\n       [0.4999793 ],\n       [0.5007446 ],\n       [0.50079525],\n       [0.50042623],\n       [0.49867725],\n       [0.49874428],\n       [0.50236475],\n       [0.49970224],\n       [0.5017068 ],\n       [0.49919462],\n       [0.49868694],\n       [0.50019795],\n       [0.5015913 ],\n       [0.49786654],\n       [0.5011241 ],\n       [0.5011297 ],\n       [0.49945524],\n       [0.5031222 ],\n       [0.5002979 ],\n       [0.49790165],\n       [0.49888813],\n       [0.49903765],\n       [0.4980083 ],\n       [0.49875113],\n       [0.5004191 ],\n       [0.49938783],\n       [0.49731672],\n       [0.50046146],\n       [0.50140643],\n       [0.49962446],\n       [0.4988155 ],\n       [0.49935144],\n       [0.500729  ],\n       [0.49848747],\n       [0.5022674 ],\n       [0.50035447],\n       [0.49938527],\n       [0.50238127],\n       [0.50045323],\n       [0.49946183],\n       [0.4994333 ],\n       [0.50301915],\n       [0.49892896],\n       [0.4979605 ],\n       [0.50172555],\n       [0.49945554],\n       [0.5001032 ],\n       [0.49953794],\n       [0.5024484 ],\n       [0.5022955 ],\n       [0.5014298 ],\n       [0.5028314 ],\n       [0.49687842],\n       [0.4993568 ],\n       [0.5005557 ],\n       [0.5004535 ],\n       [0.49989426],\n       [0.5020551 ],\n       [0.4968654 ],\n       [0.49928352],\n       [0.5005138 ],\n       [0.4994277 ],\n       [0.5015416 ],\n       [0.4999444 ],\n       [0.4973269 ],\n       [0.5011969 ],\n       [0.49926797],\n       [0.5011907 ],\n       [0.501114  ],\n       [0.5006054 ],\n       [0.50266206],\n       [0.4995033 ],\n       [0.50056285],\n       [0.49800897],\n       [0.50097233],\n       [0.50259674],\n       [0.49908856],\n       [0.49768782],\n       [0.50044954],\n       [0.49959555],\n       [0.49868953],\n       [0.5032668 ],\n       [0.500498  ],\n       [0.5018006 ],\n       [0.49706417],\n       [0.50090206],\n       [0.5028316 ],\n       [0.5001107 ],\n       [0.4992535 ],\n       [0.5009545 ],\n       [0.49970183],\n       [0.49588677],\n       [0.50012314],\n       [0.49934632],\n       [0.49893063],\n       [0.50161004],\n       [0.5002816 ],\n       [0.5036535 ],\n       [0.5009564 ],\n       [0.501216  ],\n       [0.50020397],\n       [0.49486518],\n       [0.49791685],\n       [0.5018044 ],\n       [0.49969235],\n       [0.49952006],\n       [0.5002467 ],\n       [0.5040872 ],\n       [0.49989933],\n       [0.49703977],\n       [0.49987018],\n       [0.50069517],\n       [0.49984282],\n       [0.50012624],\n       [0.4947622 ],\n       [0.5001929 ],\n       [0.4999937 ],\n       [0.49928454],\n       [0.50093603],\n       [0.5037988 ],\n       [0.5023621 ],\n       [0.49888515],\n       [0.5022236 ],\n       [0.50125694],\n       [0.5032592 ],\n       [0.5003403 ],\n       [0.4978328 ],\n       [0.49703068],\n       [0.5011864 ],\n       [0.49499816],\n       [0.49732035],\n       [0.50024736],\n       [0.5023708 ],\n       [0.50092506],\n       [0.4999571 ],\n       [0.49987647],\n       [0.5021579 ],\n       [0.49622783],\n       [0.49769592],\n       [0.49924308],\n       [0.50341785],\n       [0.50099224]], dtype=float32)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(train_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.2186 - accuracy: 0.6364 - val_loss: 0.2019 - val_accuracy: 0.6818\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2113 - accuracy: 0.6586 - val_loss: 0.1897 - val_accuracy: 0.7323\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2125 - accuracy: 0.6465 - val_loss: 0.2153 - val_accuracy: 0.6414\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.2063 - accuracy: 0.6677 - val_loss: 0.1801 - val_accuracy: 0.7273\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1970 - accuracy: 0.6848 - val_loss: 0.1739 - val_accuracy: 0.7576\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1928 - accuracy: 0.6879 - val_loss: 0.1598 - val_accuracy: 0.7727\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1803 - accuracy: 0.7232 - val_loss: 0.1483 - val_accuracy: 0.8182\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1686 - accuracy: 0.7606 - val_loss: 0.1521 - val_accuracy: 0.7828\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1594 - accuracy: 0.7859 - val_loss: 0.1451 - val_accuracy: 0.8081\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1498 - accuracy: 0.7939 - val_loss: 0.1228 - val_accuracy: 0.8586\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1396 - accuracy: 0.8121 - val_loss: 0.1108 - val_accuracy: 0.8838\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1243 - accuracy: 0.8465 - val_loss: 0.0964 - val_accuracy: 0.9091\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1146 - accuracy: 0.8525 - val_loss: 0.0930 - val_accuracy: 0.9040\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1084 - accuracy: 0.8646 - val_loss: 0.0811 - val_accuracy: 0.9040\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0910 - accuracy: 0.8919 - val_loss: 0.0744 - val_accuracy: 0.9192\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0764 - accuracy: 0.9232 - val_loss: 0.0627 - val_accuracy: 0.9293\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0669 - accuracy: 0.9303 - val_loss: 0.0482 - val_accuracy: 0.9596\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9394 - val_loss: 0.0390 - val_accuracy: 0.9798\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0486 - accuracy: 0.9586 - val_loss: 0.0297 - val_accuracy: 0.9848\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0377 - accuracy: 0.9667 - val_loss: 0.0251 - val_accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20f027dbd30>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data[0],\n",
    "    train_data[1],\n",
    "    epochs=20,\n",
    "    validation_data=(valid_x, valid_y)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.034801334142684937, 0.9646464586257935]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "('C A G G C A G A C A U G G U U U G G A A A', 0)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[1], test_y[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[0.00431074]], dtype=float32)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([prepare_single_sequence('UUUUCAUCACUAUGGCUUAGC')])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
